Welcome to Week 7!!! Some major accomplishments were made this week regarding the controls for the game, for example with gyroscope(head movements) 
controls, my team and I was able to import the gyro data onto Unity, which is the platform we're using to create the game. After importing and live-streaming
the data from the muse headset directly on that platform, we were able to test how the movement affects objects in the game in real-time by changing their sizes,
and make the required adjustments needed accordingly. Next, I specifically was able to finally detect when the muse headset wearer blinks while the headset is on 
and live-streaming neural data, which could then be possibly mapped as game controls for selecting items, menus, and other things as well in the game. A very 
exciting and quite comforting week indeed!!!
